\chapter{The Discontinous Galerkin method}	\label{ch:NumericalMethods}
This chapter aims to give an overview of the basic ideas of the DG method, as well as to present the spatial and temporal discretization of the equations presented earlier. Parts of this chapter are based on the work presented at \parencite{kummerExtendedDiscontinuousGalerkin2017,kikkerFullyCoupledHighorder, smudamartinDirectNumericalSimulation2021}, in order to maintain a consistent nomenclature with previous work where the BoSSS code is used. Additionally, the reader interested in a more in-depth description of the DG method is referred to the works of  \parencite{cockburnDevelopmentDiscontinuousGalerkin2000,hesthavenNodalDiscontinuousGalerkin2008,dipietroMathematicalAspectsDiscontinuous2012}

\section{State of the art}

\section{The Discontinous Galerkin method}

\subsection{Definitions for the discretization} \label{ssec:SpatDiscretization}
First some standard definitions and notation are introduced in the context of DG methods. 
A computational domain $\Omega \subset \mathbb{R}^2$ with a polygonal and simply connected boundary $\partial \Omega$ is defined. The numerical grid is then formed by the set of nonoverlapping elements $\gls{grid} = \{K_1, ..., K_J\}$ with a characteristic mesh size $h$, so that $\Omega$ is the union of all elements, i.e. $\Omega = \bigcup_{i=1}^J K_i$. 

Define $\Gamma = \bigcup_j \partial K_j$ as the union of all edges (internal edges and boundary edges) and $\Gamma_I = \Gamma \setminus \partial \Omega$ as the union of all interior edges.
For each edge of $\Gamma$ a normal field $\myvector{n}_{\Gamma}$ is defined. Particularly on $\partial \Omega$ is defined as an outer normal and $\vec{n}_\Gamma = \vec{n}_{\partial\Omega}$.
For each field ${u} \in C^0\left(\Omega\setminus \Gamma_I\right)$, ${u}^-$  and ${u}^+$ is defined, which describe the values of the variables on the interior and exterior sides of the cell:
\begin{align}
	{u}^- & = \lim_{\xi \searrow 0} {u}\left(\myvector{x} - \xi \myvector{n}_{\Gamma}\right) \quad \text{for } \myvector{x}\in \Gamma   \\
	{u}^+ & = \lim_{\xi \searrow 0} {u}\left(\myvector{x} + \xi \myvector{n}_{\Gamma}\right) \quad \text{for } \myvector{x}\in \Gamma_I
\end{align}
The jump and mean values of ${u}$ on the inner edges $\Gamma_I$ are defined as
\begin{align}
	\llbracket {u} \rrbracket & = {u}^+-{u}^-                           \\
	\{{u}\}                   & = \frac{1}{2} \left({u}^-+{u}^+\right).
\end{align}
while the jump and mean values on the boundary edges $\partial \Omega$ are:
\begin{align}
	\llbracket {u} \rrbracket & = {u}^-  \\
	\{{u}\}                   & = {u}^-.
\end{align}
Furthermore, the broken polynomial space of a total degree $k$ is defined as
\begin{equation}
	\mathbb{P}_k(\gls{grid} )= \{f \in L^2\left(\Omega\right); \forall K \in \gls{grid} : f\vert_{K} \text{ is polynomial and deg}\left(f\vert_{K}\right)\leq k \}.
	\label{Eq:PolSpace}
\end{equation}
Additionally, for $u \in \mathcal{C}^1(\Omega \setminus \Gamma)$ the broken gradient $\nabla_h u$ is defined as:
\begin{equation}
	\nabla_h u
	= \begin{cases}
		0
		 & \text{on }\Gamma  \\
		\nabla u
		 & \text{elsewhere }
	\end{cases}
\end{equation}
The broken divergence $\nabla_h \cdot u$ is defined analogously. Furthermore, the function space for test and trial functions for $D_v$ dependent variables is defined as
\begin{equation}
	\mathbb{V}_\myvector{k} = \prod_{i=1}^{D_v} \mathbb{P}_{k_i}(K_h)
	\label{Eq:Vspace}
\end{equation}
where $\myvector{k} = \left(k_1,...,k_{D_v}\right)$. 
Additionally, for a cell $K$ we define for $u_K$, $v_K\in \mathbb{V}_\myvector{k}$ a local inner product and a local $L^2$-norm as
\begin{equation}
(u_K, v_K)_K \coloneqq \int_K u_K v_K\text{d}x, \qquad \norm{u_K}^2_K \coloneqq(u_K,u_K)_K
\end{equation}
Similarly, for $u_h$, $v_h \in \mathbb{V}_\myvector{k}$ a global inner product and global broken norm are defined as
\begin{equation}
	(u_h, v_h)_{\Omega_h} \coloneqq \sum_{i = 1}^N (u_h, v_h)_K, \qquad \norm{u_h}^2_{\Omega_h} \coloneqq(u_h,u_h)_{\Omega_h}
\end{equation}
\subsection{Discretization using the DG Method} \label{sec:DiscWithDG}
In this subsection, the discretization by the DG method of a simple problem will be shown to demonstrate how the discretization method works and some of its specific characteristics. For this purpose, the discretization of a general conservation law for a scalar quantity $u = u(\vec{x},t)$ governed by a nonlinear flux function $\vec{f}(u)$ will be considered. In addition, suitable Dirichlet boundary conditions on $\partial \Omega = \partial \Omega_D$ and initial conditions $u_0$ are defined. The problem reads
\begin{subequations}
\begin{align}
&\pfrac{u}{t} + \nabla \cdot \vec{f}(u) = 0, \qquad\qquad\qquad &\vec{x} \in \Omega,\label{eq:consEqDG}\\
&u = u_D, \qquad \qquad \qquad  &\vec{x} \in \partial \Omega_D,\\
&u(\vec{x},0) = u_0(\vec{x}), \qquad\qquad\qquad &\vec{x}\in\Omega.
\end{align}\label{eqs:DGTransportExample}
\end{subequations}
The DG-method allows finding an approximate solution $u_h = u_h(\vec{x},t)$ for the problem \cref{eqs:DGTransportExample} by taking a linear combination of polynomial functions in each cell. 
%The error can be defined as: 
%\begin{equation}
%\gls{dgerror}(\vec{x}) = \nuM{\gls{DGVar}} - \gls{DGVar} \label{DGerror}
%\end{equation}
This approximate solution sought in the DG method is the best approximation of $\gls{DGVar} \in L^2(\gls{domain})$, which gives a minimum global error in the approximation space $\gls{DGVar} \in 	\mathbb{P}_k(\gls{domain} )$. 
\begin{align}
	\int_{\domain} (\underbrace{ \nuM{\gls{DGVar}}(x)-\gls{DGVar}(x) }_{=: \gls{dgerror}(x)})^2 \dV
	= ||\nuM{\gls{DGVar}} - \gls{DGVar}||_2^2 \rightarrow \text{min}
\end{align}
Here $\gls{dgerror}$ is the error of the discretization. Minimization is equivalent to requiring
\begin{equation}
	\label{eq:L2projection}
	\scp{r(x)}{\basis{}_m} = \scp{f_h-f}{\basis{}_m} \stackrel{!}{=} 0 \qquad \forall\basis{}_m
\end{equation}
This means that the error is orthogonal to every polynomial function $ \basis{}_m$ in the approximation space. The Bramble-Hilbert lemma \parencite{brambleEstimationLinearFunctionals1970} says, that for a $p$-times differentiable variable $\gls{DGVar}$, the error is of the order $\mathcal{O}(h^{p+1})$, which is one of the major motivations for the use of high order methods. The differentiability assumption is essential. For non smooth $\gls{DGVar}$ the well known Gibbs phenomenon occurs.

The discretization procedure starts by the approximation of the domain $\gls{domain}$ with a numerical grid $\gls{grid}$. In each cell $K_j$ of the numerical grid a set of polynomial basis $\vectr{\phi}_j = (\tilde{\phi}_{j,l})_{l=1,\dots,N_k} \in \mathbb{P}_k(\mathcal{K}_h)$ with a local cell support $\text{supp}(\phi_j) = \overline{\gls{cell}}_j$ is defined. This allows to represent the local solution for each cell $K_j$ as
\begin{equation}
u_j(\vec{x},t) = \sum_{l=1}^{N_k}\tilde{u}_{j,l}(t)\phi_{j,l}(\vec{x}) = \tilde{\vec{u}}_j(t) \cdot \vectr{\phi}_j (\vec{x})\label{eq:DGAnsatz}
\end{equation}
The coefficients $\tilde{\vectr{u}}_j = (\tilde{u}_{j,l})_{l=1,\dots,N_k}$ are the degrees of freedom (DOF) of the local solution in the cell $K_j$, which are the unknowns of the problem. Note the time dependence of the coefficients $\tilde{\vec{u}}_j$, as well as the dependence of the basis functions $\vectr{\phi}_j (\vec{x})$ on the vector $\vec{x}$. 

There are two general approaches used for the representation of the solution with the basis functions: modal and nodal. Each one of them present some advantages and disadvantages \parencite{hesthavenNodalDiscontinuousGalerkin2008}. In this work, a modal polynomial representation is used. The basis functions are chosen such that they are orthogonal to each other 
\begin{equation}
	\int_{K_j} \phi_{j,m}\phi_{j,n} \text{d}V= \delta_{mn}
\end{equation}
where $\delta_{mn}$ is the Kronecker delta. In the present work Legendre polynomials are used, since they present the orthogonality property. This property implies that matrix equals the identity matrix (at least for constant density flows).

By inserting the approximate solution in the conservation \cref{eq:consEqDG}, a local residual $R_j$ can be defined
\begin{equation}\label{eq:DGResidualeq}
R_j(\vec{x},t) = \pfrac{u_j}{t} + \nabla \cdot \vec{f}(u_j), \quad \vec{x} \in K_j
\end{equation}
Minimization of this local residual is done by multiplying \cref{eq:DGResidualeq} by the so called tests functions. In the Galerkin approach, these test functions are required to be from the same space as the trial functions, i.e. $\gls{testF}_{j,l} = \gls{basis}_{j,l}$. Thus, by multiplying \cref{eq:DGResidualeq} by a trial function and integrating over the cell $K_j$, one obtains
\begin{equation}
	\int_{\gls{cell}_j} \gls{DGres}_j \gls{testF}_{j,l} \d{V} = \int_{\gls{cell}_j}  \pDeriv{{\gls{DGVar}}_j}{t} \gls{basis}_{j,l} + \div{\gls{flux}({\gls{DGVar}}_j)} \gls{basis}_{j,l} \d{V} \stackrel{!}{=} 0, \quad \forall \vectr{\gls{basis}}_{j,l}.
	\label{eq:DGminimization}
\end{equation}
Where the minimization comes from requiring the equality to zero. Note that until this point only a cell-local discretization has been adressed. The next step for obtaining a global DG formulation is to use integration by parts for rewriting the spatial term in \cref{eq:DGminimization}, in order to explicitly make the boundary edge integrals appear. 
This is done to make the boundary edge integrals explicitly appear in the formulation, which are used to couple neighbouring cells. The partial integration process results in
 \begin{equation}
	\int_{\gls{cell}_j}  \pDeriv{{\gls{DGVar}}_j}{t} \gls{basis}_{j,l} \d{V} + \oint_{\partial{\gls{cell}}_j} \left( \gls{flux}({\gls{DGVar}}_j)\cdot{\gls{normal}}_j \right) \gls{basis}_{j,l} \d{S} - \int_{\gls{cell}_j} \gls{flux}({\gls{DGVar}}_j) \cdot \gradH{\gls{basis}}_{j,l} \d{V}  = 0, \quad \forall \gls{basis}_{j,l},
	\label{eq:DGfluxFormulation}
\end{equation} 
Note that inserting the ansatz \cref{eq:DGAnsatz} into \cref{eq:DGfluxFormulation} is problematic, since $\partial{\gls{cell}}_j$ is shared by other cells, and in the DG method continuity of a variable is not enforced across cell boundaries. This means that in general the inner value $u^{-}_j$ and the outer value $u^{+}_j$ are not equal. This problem is solved by introducing the concept of a numerical flux function, denoted here with $\gls{numflux}$
\begin{equation}
	\gls{numflux}(\inn{{\gls{DGVar}}_j}, \out{{\gls{DGVar}}_j}, \gls{normalGam}) \approx \gls{flux}({\gls{DGVar}}_j) \cdot {\gls{normal}}_j.
\end{equation}
This expression defines an unique value for the flux of a given cell boundary, enforcing flux continuity. The numerical flux $\gls{numflux}$ couples the DOFs of neighbouring cells, and should satisfy certain mathematical and physical properties which will be discussed later. Many different numerical fluxes have been developed, and it is an active area of investigation. They differ mainly in computational cost, stability and dissipation of the scheme. By introducing the numerical flux in \cref{eq:DGfluxFormulation} the problem now reads
\begin{equation}
	\int_{\gls{cell}_j}  \pDeriv{{\gls{DGVar}}_j}{t} \gls{basis}_{j,l} \d{V} + \oint_{\partial{\gls{cell}}_j} \left( \gls{numflux}(\inn{{\gls{DGVar}}_j}, \out{{\gls{DGVar}}_j}, \gls{normalGam})    \right) \gls{basis}_{j,l} \d{S} - \int_{\gls{cell}_j} \gls{flux}({\gls{DGVar}}_j) \cdot \gradH{\gls{basis}}_{j,l} \d{V}  = 0, \quad \forall \gls{basis}_{j,l},
	\label{eq:DGNumericalfluxFormulation}
\end{equation} 
\subsubsection{The global formulation}
Note that \cref{eq:DGNumericalfluxFormulation} is still a local formulation. A global solution $u(\vec{x},t)$ can be defined by a piecewise polynomial approximation according to 
\begin{equation}
	u(\vectr{x},t) \approx  u_h(\vectr{x},t) = \bigoplus\limits_{j=1}^{J} {\gls{DGVar}}_j(\vectr{x},t) = \sum_{j=1}^{J} \sum_{l=1}^{\gls{NoDOFloc}} \tilde{\gls{DGVar}}_{j,l}(t) \gls{basis}_{j,l}(\vectr{x}) \in \gls{brknPspacek}(\gls{grid})
	\label{eq:globalApprox}
\end{equation}
which corresponds to the direct sum of the $J$ local solutions $u_j$. A vector $\tilde{\vec{u}} = \tilde{\gls{DGVar}}_{1,1},\allowbreak \tilde{\gls{DGVar}}_{1,2},\allowbreak\dots, \allowbreak \tilde{\gls{DGVar}}_{j,l},\allowbreak\dots,\allowbreak\tilde{\gls{DGVar}}_{J,\gls{NoDOFloc}}\allowbreak$ which comprises the DOFs of the global approximation $\gls{DGVar}_h$ is defined, and is of length $\gls{NoDOF} = J\cdot\gls{NoDOFloc}$.%

Finally, the global formulation is obtained by inserting the ansatz \cref{eq:DGAnsatz} into \cref{eq:DGNumericalfluxFormulation}, summing over all cells $K_j$ and making use of \cref{eq:globalApprox}. The problem reads: Find $\nuM{\gls{DGVar}} \in 	\mathbb{P}_k(\gls{grid})$, such that $\forall \phi \in 	\mathbb{P}_k(\gls{grid})$
\begin{equation}
	\int_{\gls{domain}}  \pDeriv{\nuM{\gls{DGVar}}}{t} \gls{basis} \d{V}  + \oint_{\gls{edge}} \gls{numflux}(\inn{\nuM{\gls{DGVar}}}, \out{\nuM{\gls{DGVar}}}, \gls{normalGam}) \jump{\gls{basis}} \d{S} - \int_{\gls{domain}} \gls{flux}(\nuM{\gls{DGVar}}) \cdot \gradH{\gls{basis}} \d{V} = 0,
	\label{eq:semiDiscWeakForm}
\end{equation}
The solution of this system requires finding the DOFs $\tilde{\vec{u}}$ of the global approximation $\gls{DGVar}_h$. Dirichlet boundary conditions are included in the formulation by defining at $\gls{edge}_D$ the outer value $\out{\gls{DGVar}}_h = \gls{DGVar}_D$.

Note that \cref{eq:semiDiscWeakForm} is semi-discrete, meaning that the system of equations has been discretized in space, but not in time. Time discretization will be treated in \cref{ssec:TemporalDiscretization}.

Finally, after selecting suitable numerical fluxes for the various terms of the governing equations, a system is obtained that in general has the form
\begin{equation}
	 \deriv{ }{t} \left( {\gls{massM}}(\tilde{\vectr{\gls{DGVar}}})\tilde{\vectr{\gls{DGVar}}} \right) + \gls{OpM}(\tilde{\vectr{\gls{DGVar}}}) = \vectr{b},
	\label{eq:discretMatrixForm}
\end{equation}
Where $\gls{massM}$ is the mass matrix, and $\gls{OpM}$ is the operator matrix.  The vector $b$ contains the Dirichlet boundary condition. The operator matrix is defined locally by
\begin{equation}
	(\gls{OpM}_j)_{m,n} =  \oint_{\partial{\gls{cell}}_j} \gls{numflux}(\tilde{{\gls{DGVar}}}_{j,n}, \tilde{{\gls{DGVar}}}_{j^{\ast},n},\gls{normalI}) \gls{basis}_{j,m} \d{S} - \int_{\gls{cell}_j} \gls{flux}(\tilde{{\gls{DGVar}}}_{j,n} {\gls{basis}}_{j,n}) \cdot \gradH{\gls{basis}}_{j,m} \d{V} ,
	\label{eq:genOpMatrix}
\end{equation}
with $j^{\ast}$ denoting the index of a neighbour cell. The matrix $\gls{OpM}$ has block-diagonal structure, but also including extra diagonals which relate the DOFs of the cell with the neighbouring cells.

The global mass matrix is
\begin{equation}
	{\gls{massM}} =
	\left[ 
	\begin{array}{cccc}
		{\gls{massM}}_{1} & 0 & \cdots & 0 \\
		0 & {\gls{massM}}_{2} & \cdots & 0 \\
		\vdots & \vdots & \ddots & \vdots \\
		0 & 0 & \cdots & {\gls{massM}}_{J}
	\end{array}
	\right],
\end{equation} 
which is block-diagonal, since  ${\gls{massM}}_{j}$ does not depend on neighbouring cells. 
\begin{equation}
	({\gls{massM}}_j)_{m,n} = \int_{\gls{cell}_j} \gls{basis}_{j,m} \gls{basis}_{j,n} \d{V}	\label{eq:massMatrix}
\end{equation} 
The mass matrix of a cell ${\gls{massM}}_{j} := \matrixDG{M}_{(j,-) \ (j,-)} $ only depends in this case on the cell-local basis functions. 
\todo[inline]{How is the mass matrix defined for variable density flows?}

\subsubsection{Note on the numerical fluxes}
As mentioned before, the numerical fluxes $\gls{numflux}$ have to fulfil certain physical and mathematical properties for obtaining a stable and convergent method. One of the requirement for proving the stability of the scheme is the monotonicity. First, the energy estimate is defined as
\begin{equation}
	\norm{\gls{DGVar}(\vectr{x},t)}_{\gls{domain}}^2 \leq \norm{\gls{DGVar}(\vectr{x},0)}_{\gls{domain}}^2, \quad \forall t \geq 0,
	\label{eq:energyEstimate}
\end{equation}
assuming homogeneous Dirichlet boundary conditions. This means that the system is stable if the energy norm $\norm{\gls{DGVar}(\vectr{x},t)}_{\gls{domain}}^2 $ is strictly decreasing in the absence of inflow. 

For a monotonic numerical flux is possible to show that the discrete problem \cref{eq:semiDiscWeakForm} satisfies the discrete equivalent of \cref{eq:energyEstimate}. In addition to the monotonicity of the numerical flux, it is necessary that $\gls{numflux}$ is Lipschitz continuous.%, which means
%\begin{equation}
%	\label{eq:flux_lipschitz_first}
%	\exists C_a \in \mathbb{R}: \abs{\gls{numflux}(a_1, b, \vec{n}) - \hat{f}(a_2, b, \vec{n})} \leq C_a \abs{a_1 - a_2} 
%	\qquad \forall a_1, a_2 \in \mathbb{R}
%\end{equation}
%and
%\begin{equation}
%	\label{eq:flux_lipschitz_second}
%	\exists C_b \in \mathbb{R}: \abs{\gls{numflux}(a, b_1, \vec{n}) - \hat{f}(a, b_2, \vec{n})} \leq C_b \abs{b_1 - b_2} 
%	\qquad \forall b_1, b_2 \in \mathbb{R}
%\end{equation}
For the complete proof the interested reader is referred to the book from \textcite{dipietroMathematicalAspectsDiscontinuous2012}.

Two more requirements are needed for the numerical flux. The first is the consistency of the flux, which can be written as
\begin{equation}
	\gls{numflux}(a,a,\gls{normal}) = \gls{flux}(a) \cdot \gls{normal}, \quad \forall a \in \mathbb{R}. 
	\label{eq:consistency}
\end{equation}
showing that a numerical flux function should deliver the same approximate solution that the original flux function in case of a continuous variable across the interface. A direct consequence of the consistency of the numerical flux is that the weak formulation \cref{eq:semiDiscWeakForm} is automatically fulfilled by $\nuM{\gls{DGVar}} = \gls{DGVar}$.

Finally the last requirement is that the numerical flux should be conservative, which means that the total amount of $\gls{DGVar}$ can only change due to fluxes across the domain boundary. This can be written as
\begin{equation}
	\gls{numflux}(a,b,\gls{normal}) = 	-\gls{numflux}(b,a,-\gls{normal}), \quad \forall a,b \in \mathbb{R}. 
	\label{eq:conservativity}
\end{equation}
All numerical fluxes used in this work for the spatial discretization of \cref{eq:all-eqs} fulfil these requirements and they will be shown in the next section.
\subsection{Temporal discretization}\label{ssec:TemporalDiscretization}
This section will give a brief introduction to the most popular time-stepping techniques and then show the time-stepping method used in this work. This section is mainly based on \textcite{levequeFiniteVolumeMethods2002,ferzigerComputationalMethodsFluid2002}.

In the previous chapter the spatial discretization using a DG method was shown, resulting in the semi-discrete formulation given by \cref{eq:semiDiscWeakForm}. The time discretization of this semi-discrete system leads to the so called method of lines, which is the name for a method first discretized in space, and later in time.  

An alternative to the method of lines is the so called Rothe's method, where time is first discretized then the space. This can be advantageous in some cases, such as problems with a moving domain. Another alternative is the space-time approach, where basically the temporal coordinate is treated as another spatial dimension. Again, the method can be very attractive for some cases. However, the discretized schemes lead often to prohibitively large systems. These approaches are ignored in the present work, and the method of lines is adopted.

First the time discretization for a system with a constant mass matrix will be discussed. The process of discretization results often in a system of ordinary differential equations (ODEs) of the form
\begin{equation}
	\frac{\text{d}\vec{u}}{\text{d}t} = - \gls{massM}^{-1}\vec{F}(t,\vec{u}(t))\qquad \text{for}\qquad t \in (0,T).\label{eq:timestep1}
\end{equation}
with a initial condition given by $\vec{u}(t=0) = \vec{u}^0$. The main idea of a time-stepper algorithm is to discretize the time coordinate, and advance gradually the solution $\vec{u}(t^n)$ in time from values at previous time levels $\vec{u}(t^{n-1})$, $\vec{u}(t^{n-2})$, $\dots$,  until a certain final time $t = T$ is reached.
By integrating \cref{eq:timestep1} in time, one obtains
\begin{equation}
\vec{u}(t^{n+1})-\vec{u}(t^{n}) = - \gls{massM}^{-1}\int_{t^n}^{t^{n+1}}\vec{F}(t,\vec{u}(t)) \text{d}t \label{eq:timestep2}
\end{equation}
This equation is the starting point for different class of time stepping techniques. Two kind of methods can be distinguished, depending on how the integral in \cref{eq:timestep2} is evaluated: explicit methods and explicit methods. Explicit methods are obtained when the approximation of the integral is done only by using information from old time steps, while for implicit methods the information from the actual timestep is also considered, making necessary the solution of a system of equations.

The simplest example of a explicit time-stepping method is the Explicit Euler Method: $\vec{u}(t^{n+1})= \vec{u}(t^{n})  - \Delta t \gls{massM}^{-1}\vec{F}(t^n,\vec{u}(t^n))$, which is first order accurate in time. Other methods exists with better properties than the Explicit Euler Method, typically using information from multiple known time levels or a interpolation of them. Adams-Bashforth methods are a good exponent of them. 

Due to the local nature of the approach, explicit methods present themselves specially attractive for DG methods, particularly for hyperbolic equations. Explicit methods are relatively easy to implement, and need considerably less storage compared to implicit methods. However, explicit methods experience the disadvantage that, in order to obtain a stable algorithm, they are limited by a maximal timestep size $\Delta t$. The timestep typically scales with the grid size $h$ and polynomial degree $k$ by $\Delta \sim h/k$ for hyperbolic and $\Delta \sim (h/k)^2$ for parabolic problems \parencite{gassnerContributionConstructionDiffusion2007}. For many problems of interest this limitation could be highly restrictive, as too little timesteps need to be chosen in order to obtain a stable method. 

Implicit methods are specially well suited for stiff problems, as they don't suffer from the timestep limitation of explicit methods, even not being restricted at all under certain conditions, which allows using considerably bigger timesteps. They present however the inconvenience that they require the solution of a system of equations, which for large problems is not a trivial task and specialized methods could be needed.

The simplest implicit method is the Implicit Euler Method ${\vec{u}(t^{n+1})= \vec{u}(t^{n})  - \Delta t \gls{massM}^{-1}\vec{F}(t^n,\vec{u}(t^n))}$. The Implicit Euler Methods is the first method of a family of backward differentiation formulas (BDF), and presents the property of being unconditionally stable, meaning that the algorithm allows an arbitrarily large timestep. This property allows the calculation of steady state solutions just by choosing a very big $\Delta t$ value.
\todo[inline]{why?}
\begin{table}[t]
	\centering
	\begin{tabular}{lllllll}
		\hline
		$s$                   & $\gamma$ & $\beta_0$ & $\beta_1$ & $\beta_2$ & $\beta_3$ & $\beta_4$ \\ \hline
		Implicit Euler (BDF1) & 1        & 1         & -1        &           &           &           \\
		BDF2                  & 2        & 3         & -4        & 1         &           &           \\
		BDF3                  & 6        & 11        & -18       & 9         & -2        &           \\
		BDF4                  & 12       & 25        & -48       & 36        & -16       & 3         \\ \hline
	\end{tabular}
	\caption{Coefficients of the BDF schemes.}
	\label{tab:BDFCoeff}
\end{table}
In the present work BDF methods are used. In case of a non-constant mass matrix $\gls{massM}$, they have a general formula given by
\begin{equation}
	\frac{\beta_0}{\gamma\Delta t}\gls{massM}(\vec{u}(t^n))\vec{u}(t^n)- \vec{F}(\vec{u}(t^n)) = - \sum_{i=1}^s \frac{\beta_i}{\gamma \Delta t}\gls{massM}(\vec{u}(t^{n-i}))\vec{u}(t^{n-i}).
\end{equation}\label{eq:BDFDiscretization}
where $s$ is the order of the BDF-scheme. The coefficients of each schema are shown in \cref{tab:BDFCoeff}. The solution of these kind of nonlinear problems will be treated in \cref{sec:CompMethodology}.



%%%%%%%%%%%%%%%%
%. It is well known that the inclusion of the $\partial\rho /\partial t$ term of the continuity equation in the source term, as done in the present work, is a source of numerical instability. In the work of \textcite{nicoudNumericalStudyChannel} it is reported that obtaining solutions for density ratios greater than three  becomes difficult.In \textcite{rauwoensConservativeDiscreteCompatibilityconstraint2009} a similar destabilization effect is also reported for high density ratio
\textcite{nicoudConservativeHighOrderFiniteDifference2000}
Special attention should be put into the discretization of the temporal derivative appearing in the continuity equation, \cref{eq:LowMach_Conti}. It has been observed that the treating this term as a source term, for cases where high density ratios are present, is problematic \parencite{cookDirectNumericalSimulation1996,nicoudConservativeHighOrderFiniteDifference2000}. \textcite{cookDirectNumericalSimulation1996} reported for a pressure projection method, and using a third-order Adams-Bashforth scheme, that the discretization of the $\partial \rho /\partial t$ is a source of instabilities. They used a second-order explicit approximation
\begin{equation}
	\left(\frac{\partial \rho}{\partial t} \right)^n= \frac{1}{2\Delta t}\left(3\rho^n-2\rho^{n-1}+\rho^{n-2}\right)
\end{equation}
which is reported to be much more stable than a third-order approximation, by arguing that the extra dissipation from even-ordered schemas, compared to the dispersive effects of odd-ordered schemas, is helpful for the stability of the algorithm. However, they found that even with even-ordered time approximations of the density time derivative, the algorithm is stable only to maximum density variations up to a factor of three. 

This approximation of the time derivative is used in this work. Some comments in this will be done later in \cref{ch:results}
\todo[inline]{Dos preguntas: Porque tengo que incluir la densidad como un source term?}
\todo[inline]{Es valido comprar en terminos de estabilidad mi approach (implicito si se ignora eltermino drhodt) con un approach como el del pressure projection method?}
% Even-ordered finite difference approximations to this derivative
%were found to be more stable but density ratios larger than 3 are difficult to
%compute. Sandoval (reported in [6]) found that by decreasing the Reynolds
%number, larger variations in density could be achieved. Larger density ratios
%seem computable by using a predictor-corrector time-stepping algorithm in
%which the predictor uses a second-order Adams-Bashforth time integration
%4
%scheme and the corrector relies on a quasi-Crank-Nicolson integration with
%the inversion of a pressure Poisson equation at each step [7, 8]
\todo[inline]{Escribir el problema como Ax = b}
The methods for solving nonlinear problems such as the one given by \cref{eq:BDFDiscretization} be shown in \cref{sec:CompMethodology}.
\section{Discontinuous Galerkin discretization of the low-Mach equations}
The democratization methodology shown in last section is used for finding a discrete formulation of the governing equations for low-Mach reactive flows. In the next sections the discretization for the fully coupled problem with finite reaction rate, and for the flame sheet problem are shown. The chosen numerical fluxes are also shown, and some of their particularities are discussed. 

In order to ensure the validity  of the  Ladyzenskaja-Babu\u{s}ka-Brezzi (or inf-sup) condition, (see \textcite{babuskaFiniteElementMethod1973})  a mixed order formulation is used in all calculations, where polynomials of order $k$ for velocity, temperature, mass fractions and mixture fractions, and of degree $k' = k-1$ for pressure are used. This is a required compatibility condition for obtaining a well posed problem. 
\subsection{Discontinuous Galerkin discretization of the finite reaction rate problem}
Here the DG discretization of the finite reaction system defined by \crefrange{eq:LowMach_Conti}{eq:LowMachMassBalance} is presented. 
First, the vector $\vec{Y}' = \left(Y_1,\dots,Y_{N-1}\right)$ is defined as the vector containing the first $(\gls{TotalNumberSpecies}-1)$ mass fractions and $\vec{s} = \left(s_1, \dots, s_{N-1} \right)$ as the vector containing the test functions for the first $(\gls{TotalNumberSpecies}-1)$  mass fraction equations. 

The discretized form of \crefrange{eq:LowMach_Conti}{eq:LowMachMassBalance} is obtained in a similar fashion to the methodology shown in \cref{sec:DiscWithDG}. This means, each equation is multiplied by a test function, integrated it over an element $K$, applying integration by parts, using an adequate numerical flux for each term and summing over all cells in order to obtain a global formulation. Note that the convective and diffusive terms of the temperature scalars $T$, mass fraction $Y_\alpha$ and mixture fraction $z$ have the same form, so they share the same expression in their discretized form.

Finally, the discretized problem can be written as: find the numerical solution $(p_h,\vec{u}_h, T_h, \MFVecPrima_h) \in \mathbb{V}_\myvector{k}$ such that for all test functions $(q_h,\vec{v}_h, r_h, \mathbf{s}_h) \in \mathbb{V}_\myvector{k}$:
\begin{subequations}
	\begin{flalign}%
		%% Continuity
		&\gls{BCcont}(q_h)= \ContDis\ + \mathcal{T}(\partial_t \rho|_{t^{n+1}},q_h ) ,& \label{DiscretizedConti}\\[1ex]
		%% Momentum
		&\gls{BCmom}(\vec{v}_h) =	\MomConv + \MomPres + \MomDiff & \notag\\
		& \quad\quad\quad + \MomSource,& \label{DiscretizedMomentum}\\[1ex]
		%% Energy
		&\gls{BCenergy}(r_h)
		 = \mathcal{S}^C\left(\vec{u}_h,T_h,r_h, \rhoh\right) + \mathcal{S}^{D,E}\left(T_h,r_h,k/c_p(T_h)\right)&  \notag\\
		& \quad\quad\quad + \mathcal{S}^S\left(r_h, \heatRelease(T_h,\vec{Y}_h), \rateReac(T_h,\vec{Y}_h),\cph\right),& \label{DiscretizedEnergy}   \\[1ex]
	%% MassFractions
		&\gls{BCMass}(s_{\alpha h})= \mathcal{S}^C\left(\vec{u}_h,\Yi, s_{\alpha h}, \rhoh\right) + \mathcal{S}^{D,M}\left(\Yi,s_{\alpha h},\rhodh\right)&  \notag \\
		& \quad\quad\quad\quad + \mathcal{M}^S_\alpha\left(s_{\alpha h},\rateReac(T_h,\vec{Y}_h )\right).& \label{DiscretizedMassFractions}
	\end{flalign}\label{eqs:variatProblemFull}
\end{subequations}
\todo[inline]{Add the temporal terms}
where the index $\alpha$ takes values $\alpha = 1, \dots,~(\gls{TotalNumberSpecies} - 1)$. Each one of the forms introduced here are shown later in \cref{ssec:nonLinearforms}.
\subsection{Discontinuous Galerkin discretization of the flame sheet problem}
Discretizing the flame sheet problem given by \crefrange{eq:MixtFracConti2}{eq:MixtFracMF} proceeds in a similar way. Due to the similarity of the mass fraction equation and the mixture fraction equation the discretization is analogous.

The resulting problem reads: find the numerical solution $(p_h,\vec{u}_h,z_h)\in \mathbb{V}_\myvector{k}$ such that for all test functions $(q_h,\vec{v}_h,r_h)\in \mathbb{V}_\myvector{k}$ we have:
\begin{subequations}
	\begin{flalign}
		%% Continuity
		&\mathcal{B}^1(q_h)=\mathcal{C}\left(\vec{u}_h,q_h, \rho(z_h)\right),& \label{DiscretizedConti2}\\
		%% Momentum
		&\mathcal{B}^2(\vec{v}_h) =\mathcal{U}^C\left(\vec{w}_h,\vec{u}_h,\vec{v}_h, \rho(z_h)\right)+ 	\mathcal{U}^P\left(p_h,\vec{v}_h\right) +\mathcal{U}^D\left(\vec{u}_h,\vec{v}_h,\mu(z_h)\right) +\mathcal{U}^S\left(\rho(z), \vec{v}_h\right),& \label{DiscretizedMomentum2}\\
		%% Mixture Fraction	 
		&\mathcal{B}^3(r_h) = {S}^C\left(\vec{u}_h,z_h,r_h, \rho(z_h)\right) + \mathcal{S}^{D,E}\left(z_h,r_h,\rho D(z_h)\right).& \label{DiscretizedEnergy2}
	\end{flalign}\label{eqs:variatFS}
\end{subequations}
Note that density and transport parameters are dependent on the mixture fraction $z$. The evaluation of those parameters is done as mentioned in \cref{sec:FlameSheet} and solved iteratively using a Newton-Dogleg type method as shown later in \cref{sec:newton}
\subsection{Definitions of nonlinear forms}\label{ssec:nonLinearforms}
In the following the nonlinear forms used in this work are shown. Regarding the choice of fluxes, the "best practices" known in literature for the incompressible Navier-Stokes equation are followed. These fluxes proved to be well suited for all the problems discussed in this thesis, providing stability to the algorithm, while maintaining the accuracy of the solver.

It is well known \parencite{pietroMathematicalAspectsDiscontinuous2012,giraultDiscontinuousGalerkinMethod2004} that central difference fluxes for the pressure gradient and velocity divergence, combined with a coercive form for the viscous terms, e.g. symmetric interior penalty, gives a stable discretization for the Stokes equation. Furthermore, it is known that for all kinds of convective terms, a numerical flux which transports information in characteristic direction, e.g. Upwind, Lax-Friedrichs or Local-Lax-Friedrichs, must be used. We opted for the last one in the present implementation, as it offers a good compromise between accuracy and stability.
\paragraph{Continuity equation}
A central difference flux for the discretization of the continuity equation is used:
\begin{equation}
	\mathcal{C}(\vec{u},q, \rho)  =  \oint_{\GammaI \cup\GammaN\cup \GammaND\cup \GammaP}{\mean{\rho\vec{u} }\cdot \vec{n}_\Gamma\jump{q} \dS} - \int_{\Omega}{\rho \vec{u}\cdot \nabla_h q} \dV.  \label{eq:Conti}
\end{equation}
The density in \cref{eq:Conti} is evaluated as a function of the temperature and mass fractions using the equation of state (\cref{eq:ideal_gas}). The term $\mathcal{B}^1$ on the left hand sides of \cref{DiscretizedConti} and \cref{DiscretizedConti2}  contains the Dirichlet boundary conditions:
\begin{equation}
	\mathcal{B}^1(q) =  -\oint_{\GammaD\cup \GammaDW}{q(\rho_{\text{D}} \vec{u}_{\text{D}} \cdot \normalBoundary). \dS}
\end{equation}
The density at the boundary  $\rho_{\text{D}}$ is evaluated with \cref{eq:ideal_gas} using the corresponding Dirichlet values of temperature and mass fractions.
\begin{equation}
\mathcal{T}() =   \int_{\Omega}{  ? q} \dV.
\end{equation}
\todo[inline]{Add the source term for the continuity equation}
\paragraph{Momentum equations}
The convective term of the momentum equations is discretized using a Lax-Friedrichs flux
\begin{equation}
	\mathcal{U}^C(\vec{w},\vec{u},\vec{v}, \rho)=  \oint_{\Gamma}{\left( \mean{\rho\vec{u}\otimes\vec{w} }\vec{n}_\Gamma + \frac{\gamma_1}{2}\jump{\vec{u}}\right)\cdot\jump{\vec{v}} \dS}
	-\int_{\Omega}({\rho\vec{u}\otimes\vec{w}}):\nabla_h\vec{v} d\text{V}.
	\label{eq:Mom_convective}\\
\end{equation}
The Lax-Friedrichs parameter $\gamma_1$ is calculated as \textcite{kleinHighorderDiscontinuousGalerkin2016}
\begin{equation}
	\gamma_1  = \max \left\{2 \overline{\rho^+} |\overline{\vec{u}^+} \cdot \vec{n}^+|,2 \overline{\rho^-} |\overline{\vec{u}^-} \cdot \vec{n}^-|\right\},
	\label{eq:vardens_lambda}
\end{equation}
\todo[inline]{How is this actually implemented?}
where $\overline{\rho_{h}^\pm}$ and $\overline{\vec{u}^\pm}$ are the mean values of $\rho^\pm$ and $\vec{u}^\pm$ in $K^\pm$, respectively.\\
The pressure term is discretized by using a central difference flux
\begin{equation}
	\mathcal{U}^P(p,\vec{v})=  \oint_{\Gamma \setminus \Gamma_{\text{N}}\setminus \Gamma_{\text{ND}}}{ \mean{p}(\jump{\vec{v}}\cdot \vec{n}_\Gamma  )\dS}
	- \int_{\Omega}{p \nabla_h \cdot \vec{v} \dV}. \label{eq:Mom_pressure}
\end{equation}
The diffusive term of the momentum equations is discretized using an Symmetric Interior Penalty (SIP)  formulation \parencite{shahbaziExplicitExpressionPenalty2005}
\begin{equation}
	\begin{aligned}
		\tilde{\mathcal{U}}^D(\vec{u},\vec{v},\mu) =
		  & \int_{\Omega}{\left(\mu\left((\nabla_h \vec{u}) + (\nabla_h \vec{u})^T - \frac{2}{3}(\nabla_h\cdot \vec{u})\mytensor{I} \right)\right)\colon \nabla_h\vec{v}} \dV \\
		- & \oint_{\Gamma \setminus \Gamma_{\text{N}}\setminus \Gamma_{\text{ND}}}
		\left(\mean{\mu(\nabla_h\vec{u} + \nabla_h\vec{u}^T - \frac{2}{3}(\nabla_h\cdot \vec{u})\mytensor{I})}\normalBoundary\right)\cdot\jump{\vec{v}}\dS                    \\
		- & \oint_{\Gamma \setminus \Gamma_{\text{N}}\setminus \Gamma_{\text{ND}}}
		\left(\mean{\mu(\nabla_h\vec{v} + \nabla_h\vec{v}^T - \frac{2}{3}(\nabla_h\cdot \vec{v})\mytensor{I})}\normalBoundary\right)\cdot\jump{\vec{u}} \dS                   \\
		+ & \oint_{\Gamma \setminus \Gamma_{\text{N}}\setminus \Gamma_{\text{ND}}} \eta \mu_{\text{max}} \jump{\vec{u}} \jump{\vec{v}}\dS.
		\label{eq:Mom_diffusive}
	\end{aligned}
\end{equation}
The viscosity $\mu$ is evaluated as a function of temperature according to \cref{eq:nondim_sutherland} and $\mu_{\text{max}} = \text{max}(\mu^{+}, \mu^{-})$.  Additionally  $\eta$ is the penalty term of the SIP formulation, which has to be chosen big enough to ensure coercivity of the form, but also as small as possible in order to not increase the condition number of the problem. The estimation of the penalty term is based on an expression of the form
\begin{equation}
	\eta = \eta_0 \frac{A(\partial K)}{V(K)},
\end{equation}\label{eq:PenaltyFactor}
where for a two-dimensional problem $A$ is the perimeter and $V$ the area of the element. Parameter $\eta_0$ is a safety factor. If not stated otherwise, the value  $\eta_0 = 4$ is  set in all calculations. Further information on the determination of the penalty term of the SIP formulation $\eta$ and the penalty term of the Lax-Friedrichs $\gamma_1 $ can be found in  the works from \textcite{hesthavenNodalDiscontinuousGalerkin2008} and \textcite{hillewaertDevelopmentDiscontinuousGalerkin2013}.

Note that the diffusive term of the momentum equations is scaled by the Reynolds number, obtaining finally
\begin{equation}
		\mathcal{U}^D(\vec{u},\vec{v},\mu) = 	\frac{1}{\Reynolds}\tilde{\mathcal{U}}^D(\vec{u},\vec{v},\mu)
\end{equation}

The source term arising due to body forces is:
\begin{equation}
	\mathcal{U}^S\left(\rho, \vec{v}\right) =  \smash{\frac{1}{\Froude^2}}\int_{\Omega}{  \rho \frac{\vec{g}}{\Vert \vec{g} \Vert}\cdot \vec{v}} \dV.  \label{eq:Mom_source}
\end{equation}
Finally, the right hand sides of \cref{DiscretizedMomentum} and \cref{DiscretizedMomentum2} contain the information from Dirichlet boundary conditions:
\begin{equation}
	\mathcal{B}^2(\vec{v}) =
	-\oint_{\Gamma_{\text{D}}}{ \left( (\rho\vec{u}_{\text{D}}\otimes\vec{u}_{\text{D}} )\normalBoundary + \frac{\gamma_1}{2}\vec{u}_{\text{D}}\right)\cdot\vec{v} \dS}  +
	\oint_{\Gamma_{\text{D}}}{\mu_{\text{D}}\vec{u}_{\text{D}}\cdot(\nabla_h\vec{v} \normalBoundary + \nabla_h\vec{v}^T \normalBoundary- \eta \vec{v} )\dS.}
\end{equation}
The Dirichlet viscosity value $\mu_{\text{D}}$ is calculated from \cref{eq:nondim_sutherland} using the Dirichlet values of the temperature at the boundary.
\paragraph{Scalar equations}
Since the convective and diffusive term for the temperature, mass fractions and mixture fraction share a similar form,  here their discretized expressions are summarized in terms of an arbitrary scalar $X$ (corresponding to $T$ in the energy equation, $Y_\alpha$ in the equation for species $\alpha$ and $z$ for the mixture fraction equation) and transport parameter $\xi$ (i.e. $k/c_p$ in the energy equation, and $(\rho D)$ for the mass fraction and mixture fraction equations). The convective term of the scalars is discretized using a Lax-Friedrichs flux
\begin{equation}
	\mathcal{S}^C(\vec{u},X,r, \rho) =  \oint_{\Gamma}{\left( \mean{\rho\vec{u}X }\cdot \vec{n} + \frac{\gamma_2}{2}\jump{X}\right)\jump{r} \dS}
	- \int_{\Omega}({\rho \vec{u} X \cdot \nabla_h r) d\text{V}}. \label{eq:scalar_convective}
\end{equation}
The Lax-Friedrichs parameter $\gamma_2$ is calculated as 
\begin{equation}
	\gamma_2  = \max \left\{\overline{\rho^+} |\overline{\vec{u}^+} \cdot \vec{n}^+|,\overline{\rho^-} |\overline{\vec{u}^-} \cdot \vec{n}^-|\right\}.
	\label{eq:vardens_lambda2}
\end{equation}
The diffusion term of scalars is discretized again with a SIP formulation:
\begin{align}
	\mathcal{S}^D(X,r,\xi)= & \int_{\Omega}{ \left(\xi \nabla_h X \cdot\nabla_h r\right) }\dV \notag         \\
	                        & -\oint_{\Gamma \setminus \Gamma_{\text{N}}\setminus \Gamma_{\text{ND}}}{\left(
		\mean{\xi \nabla_h X}\cdot \vec{n}\jump{r} +
		\mean{\xi \nabla_h r}\cdot \vec{n}\jump{X} -
		\eta \xi_{\text{max}} \jump{X} \jump{r}
		\right) \dS.
	} \label{eq:Temp_diffusive}
\end{align}
The transport parameter $\xi$ is calculated as a function of temperature using \cref{eq:nondim_sutherland} and $\xi_{\text{max}} = \text{max}(\xi^{+}, \xi^{-})$.
The diffusive term for the temperature equation  and mixture fraction equation is scaled by the Reynolds and Prandtl number as
\begin{equation}
\mathcal{S}^{D,E}\left(T,r,k/c_p\right) = \frac{1}{\Reynolds~\Prandtl} \mathcal{S}^D(T,r,k/c_p)
\end{equation}
Simmilarly the diffusive term for the mass fraction equations is
\begin{equation}
\mathcal{S}^{D,M}\left(\Yi,s_{\alpha h},\rho D_\alpha\right) = \frac{1}{\Reynolds~\Prandtl~\Lewis_\alpha} \mathcal{S}^D\left(\Yi,s_{\alpha h},\rho D_\alpha\right)
\end{equation}
The boundary condition term of the corresponding scalar equation is:
\begin{equation}
	\mathcal{B}^3(r) =  -
	\oint_{\GammaD\cup \GammaND}{ \left( (\rho_D\vec{u}_D X_D)\cdot \normalBoundary + \frac{\gamma_2}{2}X_D\right)r \dS}
	+\oint_{\GammaD\cup \GammaND} \xi_D X_D(\nabla_h r \cdot \normalBoundary - \eta r )\dS.
\end{equation}
Here, $X_D$ is the Dirichlet value of the scalar $X$ on boundaries and $\xi_D$ is the corresponding transport parameter calculated,which is calculated with \cref{eq:nondim_sutherland} using the Dirichlet values of the temperature at the boundary.
Finally, the volumetric source term of the energy and mass fraction equations are defined as follows:
\begin{gather}
	\mathcal{S}^S(r,\heatRelease, \rateReac,c_p) =  \text{H}~\Da ~ \int_{\Omega}{ \frac{\heatRelease \rateReac}{c_p} r} \dV, \\
	\mathcal{M}^S_\alpha(s_\alpha,\rateReac ) =  \Da \int_{\Omega}{  \stoicCoef_\alpha M_\alpha \rateReac s_\alpha} \dV.
\end{gather}
The heat release $\heatRelease$ is calculated with \cref{eq:heatReleaseOneStepNonDim}, the reaction rate $\rateReac$ is evaluated using \cref{eq:NonDimArr} and the mixture heat capacity with \cref{eq:nondim_cpmixture}.

